{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b2b527b2-70a9-47eb-abb1-4f220d84a68b",
   "metadata": {},
   "source": [
    "TEST TOKENIZER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "51baea2d-28c6-4419-bade-6d9d2beeebe9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>/* Styles used for the Hoogle display in the pager */\n",
       ".hoogle-doc {\n",
       "display: block;\n",
       "padding-bottom: 1.3em;\n",
       "padding-left: 0.4em;\n",
       "}\n",
       ".hoogle-code {\n",
       "display: block;\n",
       "font-family: monospace;\n",
       "white-space: pre;\n",
       "}\n",
       ".hoogle-text {\n",
       "display: block;\n",
       "}\n",
       ".hoogle-name {\n",
       "color: green;\n",
       "font-weight: bold;\n",
       "}\n",
       ".hoogle-head {\n",
       "font-weight: bold;\n",
       "}\n",
       ".hoogle-sub {\n",
       "display: block;\n",
       "margin-left: 0.4em;\n",
       "}\n",
       ".hoogle-package {\n",
       "font-weight: bold;\n",
       "font-style: italic;\n",
       "}\n",
       ".hoogle-module {\n",
       "font-weight: bold;\n",
       "}\n",
       ".hoogle-class {\n",
       "font-weight: bold;\n",
       "}\n",
       ".get-type {\n",
       "color: green;\n",
       "font-weight: bold;\n",
       "font-family: monospace;\n",
       "display: block;\n",
       "white-space: pre-wrap;\n",
       "}\n",
       ".show-type {\n",
       "color: green;\n",
       "font-weight: bold;\n",
       "font-family: monospace;\n",
       "margin-left: 1em;\n",
       "}\n",
       ".mono {\n",
       "font-family: monospace;\n",
       "display: block;\n",
       "}\n",
       ".err-msg {\n",
       "color: red;\n",
       "font-style: italic;\n",
       "font-family: monospace;\n",
       "white-space: pre;\n",
       "display: block;\n",
       "}\n",
       "#unshowable {\n",
       "color: red;\n",
       "font-weight: bold;\n",
       "}\n",
       ".err-msg.in.collapse {\n",
       "padding-top: 0.7em;\n",
       "}\n",
       ".highlight-code {\n",
       "white-space: pre;\n",
       "font-family: monospace;\n",
       "}\n",
       ".suggestion-warning { \n",
       "font-weight: bold;\n",
       "color: rgb(200, 130, 0);\n",
       "}\n",
       ".suggestion-error { \n",
       "font-weight: bold;\n",
       "color: red;\n",
       "}\n",
       ".suggestion-name {\n",
       "font-weight: bold;\n",
       "}\n",
       "</style><div class=\"suggestion-name\" style=\"clear:both;\">Use fewer imports</div><div class=\"suggestion-row\" style=\"float: left;\"><div class=\"suggestion-warning\">Found:</div><div class=\"highlight-code\" id=\"haskell\">import Data.Word\n",
       "import Data.Word ( Word8 )\n",
       "</div></div><div class=\"suggestion-row\" style=\"float: left;\"><div class=\"suggestion-warning\">Why Not:</div><div class=\"highlight-code\" id=\"haskell\">import Data.Word\n",
       "</div></div>"
      ],
      "text/plain": [
       "Line 6: Use fewer imports\n",
       "Found:\n",
       "import Data.Word\n",
       "import Data.Word ( Word8 )\n",
       "\n",
       "Why not:\n",
       "import Data.Word"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import qualified Data.ByteString as BS\n",
    "import qualified Data.ByteString.Lazy as B\n",
    "import qualified Data.ByteString.Lazy.Char8 as BL\n",
    "import qualified Data.ByteString.UTF8 as BSU\n",
    "import Data.Aeson (decode)\n",
    "import Data.Word\n",
    "import qualified Data.Map as Map\n",
    "import Data.Maybe (fromMaybe)\n",
    "import System.IO\n",
    "import Data.List.Split (splitOn)\n",
    "import Distribution.Simple\n",
    "import qualified Data.Text as T\n",
    "import qualified Data.Text.IO as TIO\n",
    "import Data.Char (chr, ord)\n",
    "import Data.Word (Word8)\n",
    "\n",
    "type CharMap = Map.Map String Int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6487e041-6994-43a6-b7f9-19ec85a107fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "loadJSON :: FilePath -> IO (Maybe CharMap)\n",
    "loadJSON filePath = do\n",
    "  content <- B.readFile filePath\n",
    "  return $ decode content\n",
    "  \n",
    "readFileToPairs :: FilePath -> String -> IO [(String, String)]\n",
    "readFileToPairs filePath delimiter = do\n",
    "    content <- readFile filePath\n",
    "    let lines' = lines content         -- Diviser en lignes\n",
    "        pairs = map (toPair delimiter) lines'   -- Convertir chaque ligne en tuple\n",
    "    return pairs\n",
    "  where\n",
    "    -- Fonction pour convertir une ligne en tuple (s1, s2)\n",
    "    toPair :: String -> String -> (String, String)\n",
    "    toPair delim line = \n",
    "        case splitOn delim line of\n",
    "            [first, second] -> (first, second)  -- Cas normal: deux parties\n",
    "      \n",
    "maybeVocab <- loadJSON \"vocab.json\"\n",
    "pairs <- readFileToPairs \"merges.txt\" \" \"\n",
    "\n",
    "getVocab :: Maybe CharMap -> IO CharMap\n",
    "getVocab maybeVocab =\n",
    "    case maybeVocab of\n",
    "        Just vocab -> return vocab\n",
    "        Nothing    -> do\n",
    "            putStrLn \"Erreur: vocab non chargé\"\n",
    "            return Map.empty\n",
    "    \n",
    "fullVocab <- getVocab maybeVocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "73957b82-f42e-4c76-b6f3-efb922f144d0",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "<interactive>:1:26: error: Variable not in scope: result :: String"
     ]
    }
   ],
   "source": [
    "toByte :: FilePath -> IO String\n",
    "toByte path = do\n",
    "    bs <- BS.readFile path\n",
    "    let toW8 = BS.unpack bs\n",
    "    return (BSU.toString (BS.pack toW8))\n",
    "    \n",
    "resultToByte <- toByte \"testTexte.txt\"\n",
    "\n",
    "putStrLn (\"result: \"  ++ result)\n",
    "putStrLn \"expect: Lights flicker. She waits. Time forgets to move.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "673c9214-fa0b-469d-b62a-9dd689c162c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "result: LightsĠflicker.ĠSheĠwaits.ĠTimeĠforgetsĠtoĠmove."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "expect: LightsĠflicker.ĠSheĠwaits.ĠTimeĠforgetsĠtoĠmove."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "replaceSpace :: String -> String\n",
    "replaceSpace input = \n",
    "    T.unpack (T.replace (T.pack \" \") (T.pack \"Ġ\") (T.pack input))\n",
    "\n",
    "putStrLn (\"result: \" ++ replaceSpace \"Lights flicker. She waits. Time forgets to move.\")\n",
    "putStrLn \"expect: LightsĠflicker.ĠSheĠwaits.ĠTimeĠforgetsĠtoĠmove.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c4ca5e47-11d6-458e-b750-ff6a0e4d3af6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>/* Styles used for the Hoogle display in the pager */\n",
       ".hoogle-doc {\n",
       "display: block;\n",
       "padding-bottom: 1.3em;\n",
       "padding-left: 0.4em;\n",
       "}\n",
       ".hoogle-code {\n",
       "display: block;\n",
       "font-family: monospace;\n",
       "white-space: pre;\n",
       "}\n",
       ".hoogle-text {\n",
       "display: block;\n",
       "}\n",
       ".hoogle-name {\n",
       "color: green;\n",
       "font-weight: bold;\n",
       "}\n",
       ".hoogle-head {\n",
       "font-weight: bold;\n",
       "}\n",
       ".hoogle-sub {\n",
       "display: block;\n",
       "margin-left: 0.4em;\n",
       "}\n",
       ".hoogle-package {\n",
       "font-weight: bold;\n",
       "font-style: italic;\n",
       "}\n",
       ".hoogle-module {\n",
       "font-weight: bold;\n",
       "}\n",
       ".hoogle-class {\n",
       "font-weight: bold;\n",
       "}\n",
       ".get-type {\n",
       "color: green;\n",
       "font-weight: bold;\n",
       "font-family: monospace;\n",
       "display: block;\n",
       "white-space: pre-wrap;\n",
       "}\n",
       ".show-type {\n",
       "color: green;\n",
       "font-weight: bold;\n",
       "font-family: monospace;\n",
       "margin-left: 1em;\n",
       "}\n",
       ".mono {\n",
       "font-family: monospace;\n",
       "display: block;\n",
       "}\n",
       ".err-msg {\n",
       "color: red;\n",
       "font-style: italic;\n",
       "font-family: monospace;\n",
       "white-space: pre;\n",
       "display: block;\n",
       "}\n",
       "#unshowable {\n",
       "color: red;\n",
       "font-weight: bold;\n",
       "}\n",
       ".err-msg.in.collapse {\n",
       "padding-top: 0.7em;\n",
       "}\n",
       ".highlight-code {\n",
       "white-space: pre;\n",
       "font-family: monospace;\n",
       "}\n",
       ".suggestion-warning { \n",
       "font-weight: bold;\n",
       "color: rgb(200, 130, 0);\n",
       "}\n",
       ".suggestion-error { \n",
       "font-weight: bold;\n",
       "color: red;\n",
       "}\n",
       ".suggestion-name {\n",
       "font-weight: bold;\n",
       "}\n",
       "</style><div class=\"suggestion-name\" style=\"clear:both;\">Redundant bracket</div><div class=\"suggestion-row\" style=\"float: left;\"><div class=\"suggestion-warning\">Found:</div><div class=\"highlight-code\" id=\"haskell\">([\"H\", \"i\", \",\", \" \", \"l\", \"e\", \"t\", \"s\", \" \", \"t\", \"o\", \"k\", \"e\",\n",
       "  \"n\", \"i\", \"z\", \"e\"])</div></div><div class=\"suggestion-row\" style=\"float: left;\"><div class=\"suggestion-warning\">Why Not:</div><div class=\"highlight-code\" id=\"haskell\">[\"H\", \"i\", \",\", \" \", \"l\", \"e\", \"t\", \"s\", \" \", \"t\", \"o\", \"k\", \"e\",\n",
       " \"n\", \"i\", \"z\", \"e\"]</div></div>"
      ],
      "text/plain": [
       "Line 8: Redundant bracket\n",
       "Found:\n",
       "([\"H\", \"i\", \",\", \" \", \"l\", \"e\", \"t\", \"s\", \" \", \"t\", \"o\", \"k\", \"e\",\n",
       "  \"n\", \"i\", \"z\", \"e\"])\n",
       "Why not:\n",
       "[\"H\", \"i\", \",\", \" \", \"l\", \"e\", \"t\", \"s\", \" \", \"t\", \"o\", \"k\", \"e\",\n",
       " \"n\", \"i\", \"z\", \"e\"]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "result:"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[\"H\",\"i\",\",\",\" \",\"l\",\"e\",\"t\",\"s\",\" \",\"t\",\"o\",\"k\",\"e\",\"n\",\"i\",\"z\",\"e\"]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "expect:"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[\"H\",\"i\",\",\",\" \",\"l\",\"e\",\"t\",\"s\",\" \",\"t\",\"o\",\"k\",\"e\",\"n\",\"i\",\"z\",\"e\"]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "makeStrArray :: String -> [String]\n",
    "makeStrArray =\n",
    "    map (:[])\n",
    "\n",
    "putStrLn \"result: \"\n",
    "print (makeStrArray \"Hi, lets tokenize\")\n",
    "putStrLn \"expect: \"\n",
    "print ([\"H\",\"i\",\",\",\" \",\"l\",\"e\",\"t\",\"s\",\" \",\"t\",\"o\",\"k\",\"e\",\"n\",\"i\",\"z\",\"e\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "21ceefd5-f665-4a50-b2b0-f75a9f7e4787",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "result:"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[\"ab\",\"c\"]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "expect:"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[\"ab\",\"c\"]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "result:"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[\"ab\",\"ab\",\"d\"]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "expect:"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[\"ab\",\"ab\",\"d\"]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "result:"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[\"a\",\"b\",\"c\"]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "expect:"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[\"a\",\"b\",\"c\"]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "result:"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[\"a\"]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "expect:"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[\"a\"]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "result:"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "expect:"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "result:"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[\"ab\",\"b\",\"c\"]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "expect:"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[\"ab\",\"b\",\"c\"]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "merge :: (String, String) -> [String] -> [String]\n",
    "merge _ [] = []\n",
    "merge _ [x] = [x]\n",
    "merge (a, b) (x1:x2:xs)\n",
    "  | x1 == a && x2 == b = (a ++ b) : merge (a, b) xs\n",
    "  | otherwise          = x1 : merge (a, b) (x2:xs)\n",
    "  \n",
    "putStrLn \"result: \"\n",
    "print (merge (\"a\", \"b\") [\"a\", \"b\", \"c\"])\n",
    "putStrLn \"expect: \"\n",
    "print [\"ab\", \"c\"]\n",
    "\n",
    "putStrLn \"result: \"\n",
    "print (merge (\"a\", \"b\") [\"a\", \"b\", \"a\", \"b\", \"d\"])\n",
    "putStrLn \"expect: \"\n",
    "print [\"ab\", \"ab\", \"d\"]\n",
    "\n",
    "putStrLn \"result: \"\n",
    "print (merge (\"x\", \"y\") [\"a\", \"b\", \"c\"])\n",
    "putStrLn \"expect: \"\n",
    "print [\"a\", \"b\", \"c\"]\n",
    "\n",
    "\n",
    "putStrLn \"result: \"\n",
    "print (merge (\"a\", \"b\") [\"a\"])\n",
    "putStrLn \"expect: \"\n",
    "print [\"a\"]\n",
    "\n",
    "\n",
    "putStrLn \"result: \"\n",
    "print (merge (\"a\", \"b\") [])\n",
    "putStrLn \"expect: \"\n",
    "print []\n",
    "\n",
    "putStrLn \"result: \"\n",
    "print (merge (\"a\", \"b\") [\"a\", \"b\", \"b\", \"c\"])\n",
    "putStrLn \"expect: \"\n",
    "print [\"ab\", \"b\", \"c\"]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "982980e1-f606-47e8-83ae-5835db7ebbf9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>/* Styles used for the Hoogle display in the pager */\n",
       ".hoogle-doc {\n",
       "display: block;\n",
       "padding-bottom: 1.3em;\n",
       "padding-left: 0.4em;\n",
       "}\n",
       ".hoogle-code {\n",
       "display: block;\n",
       "font-family: monospace;\n",
       "white-space: pre;\n",
       "}\n",
       ".hoogle-text {\n",
       "display: block;\n",
       "}\n",
       ".hoogle-name {\n",
       "color: green;\n",
       "font-weight: bold;\n",
       "}\n",
       ".hoogle-head {\n",
       "font-weight: bold;\n",
       "}\n",
       ".hoogle-sub {\n",
       "display: block;\n",
       "margin-left: 0.4em;\n",
       "}\n",
       ".hoogle-package {\n",
       "font-weight: bold;\n",
       "font-style: italic;\n",
       "}\n",
       ".hoogle-module {\n",
       "font-weight: bold;\n",
       "}\n",
       ".hoogle-class {\n",
       "font-weight: bold;\n",
       "}\n",
       ".get-type {\n",
       "color: green;\n",
       "font-weight: bold;\n",
       "font-family: monospace;\n",
       "display: block;\n",
       "white-space: pre-wrap;\n",
       "}\n",
       ".show-type {\n",
       "color: green;\n",
       "font-weight: bold;\n",
       "font-family: monospace;\n",
       "margin-left: 1em;\n",
       "}\n",
       ".mono {\n",
       "font-family: monospace;\n",
       "display: block;\n",
       "}\n",
       ".err-msg {\n",
       "color: red;\n",
       "font-style: italic;\n",
       "font-family: monospace;\n",
       "white-space: pre;\n",
       "display: block;\n",
       "}\n",
       "#unshowable {\n",
       "color: red;\n",
       "font-weight: bold;\n",
       "}\n",
       ".err-msg.in.collapse {\n",
       "padding-top: 0.7em;\n",
       "}\n",
       ".highlight-code {\n",
       "white-space: pre;\n",
       "font-family: monospace;\n",
       "}\n",
       ".suggestion-warning { \n",
       "font-weight: bold;\n",
       "color: rgb(200, 130, 0);\n",
       "}\n",
       ".suggestion-error { \n",
       "font-weight: bold;\n",
       "color: red;\n",
       "}\n",
       ".suggestion-name {\n",
       "font-weight: bold;\n",
       "}\n",
       "</style><div class=\"suggestion-name\" style=\"clear:both;\">Use foldl</div><div class=\"suggestion-row\" style=\"float: left;\"><div class=\"suggestion-warning\">Found:</div><div class=\"highlight-code\" id=\"haskell\">merges [] tokens = tokens\n",
       "merges (pair : pairs) tokens = merges pairs (merge pair tokens)</div></div><div class=\"suggestion-row\" style=\"float: left;\"><div class=\"suggestion-warning\">Why Not:</div><div class=\"highlight-code\" id=\"haskell\">merges pairs tokens = foldl (flip merge) tokens pairs</div></div>"
      ],
      "text/plain": [
       "Line 2: Use foldl\n",
       "Found:\n",
       "merges [] tokens = tokens\n",
       "merges (pair : pairs) tokens = merges pairs (merge pair tokens)\n",
       "Why not:\n",
       "merges pairs tokens = foldl (flip merge) tokens pairs"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "Test 1 – fusion simple"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[\"ab\",\"c\"]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[\"ab\",\"c\"]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "Test 2 – fusion multiple identique"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[\"ab\",\"ab\",\"d\"]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[\"ab\",\"ab\",\"d\"]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "Test 3 – aucune fusion possible"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[\"a\",\"b\",\"c\"]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[\"a\",\"b\",\"c\"]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "Test 4 – liste avec un seul élément"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[\"a\"]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[\"a\"]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "Test 5 – liste vide"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "Test 6 – fusion + éléments restants"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[\"ab\",\"b\",\"c\"]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[\"ab\",\"b\",\"c\"]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "Test 7 – deux règles qui s’enchaînent"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[\"abc\",\"d\"]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[\"abc\",\"d\"]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "Test 8 – ordre des règles inversé"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[\"ab\",\"c\",\"d\"]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[\"ab\",\"c\",\"d\"]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "Test 9 – fusion récursive sur plusieurs niveaux"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[\"abc\"]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[\"abc\"]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "Test 10 – chaîne très longue"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[\"hello\"]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[\"hello\"]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "Test 11 – fusion partielle seulement"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[\"ab\",\"x\",\"z\"]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[\"ab\",\"x\",\"z\"]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "Test 12 – fusion qui ne change rien"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[\"a\",\"b\",\"c\"]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[\"a\",\"b\",\"c\"]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "merges :: [(String, String)] -> [String] -> [String]\n",
    "merges [] tokens = tokens\n",
    "merges (pair:pairs) tokens = merges pairs (merge pair tokens)\n",
    "\n",
    "putStrLn \"\\nTest 1 – fusion simple\"\n",
    "print (merges [(\"a\", \"b\")] [\"a\", \"b\", \"c\"])\n",
    "print [\"ab\", \"c\"]\n",
    "\n",
    "putStrLn \"\\nTest 2 – fusion multiple identique\"\n",
    "print (merges [(\"a\", \"b\")] [\"a\", \"b\", \"a\", \"b\", \"d\"])\n",
    "print [\"ab\", \"ab\", \"d\"]\n",
    "\n",
    "putStrLn \"\\nTest 3 – aucune fusion possible\"\n",
    "print (merges [(\"x\", \"y\")] [\"a\", \"b\", \"c\"])\n",
    "print [\"a\", \"b\", \"c\"]\n",
    "\n",
    "putStrLn \"\\nTest 4 – liste avec un seul élément\"\n",
    "print (merges [(\"a\", \"b\")] [\"a\"])\n",
    "print [\"a\"]\n",
    "\n",
    "putStrLn \"\\nTest 5 – liste vide\"\n",
    "print (merges [(\"a\", \"b\")] [])\n",
    "print []\n",
    "\n",
    "putStrLn \"\\nTest 6 – fusion + éléments restants\"\n",
    "print (merges [(\"a\", \"b\")] [\"a\", \"b\", \"b\", \"c\"])\n",
    "print [\"ab\", \"b\", \"c\"]\n",
    "\n",
    "putStrLn \"\\nTest 7 – deux règles qui s’enchaînent\"\n",
    "print (merges [(\"a\", \"b\"), (\"ab\", \"c\")] [\"a\", \"b\", \"c\", \"d\"])\n",
    "print [\"abc\", \"d\"]\n",
    "\n",
    "putStrLn \"\\nTest 8 – ordre des règles inversé\"\n",
    "print (merges [(\"ab\", \"c\"), (\"a\", \"b\")] [\"a\", \"b\", \"c\", \"d\"])\n",
    "print [\"ab\", \"c\", \"d\"] -- car \"ab\" n'existe pas encore au premier passage\n",
    "\n",
    "putStrLn \"\\nTest 9 – fusion récursive sur plusieurs niveaux\"\n",
    "print (merges [(\"a\", \"b\"), (\"b\", \"c\"), (\"ab\", \"c\"), (\"abc\", \"d\")] [\"a\", \"b\", \"c\"])\n",
    "print [\"abc\"] -- ou [\"a\", \"bc\"] si certaines règles sont mal ordonnées\n",
    "\n",
    "putStrLn \"\\nTest 10 – chaîne très longue\"\n",
    "print (merges [(\"h\", \"e\"), (\"he\", \"l\"), (\"hel\", \"l\"), (\"hell\", \"o\")] [\"h\", \"e\", \"l\", \"l\", \"o\"])\n",
    "print [\"hello\"]\n",
    "\n",
    "putStrLn \"\\nTest 11 – fusion partielle seulement\"\n",
    "print (merges [(\"a\", \"b\"), (\"x\", \"y\")] [\"a\", \"b\", \"x\", \"z\"])\n",
    "print [\"ab\", \"x\", \"z\"]\n",
    "\n",
    "putStrLn \"\\nTest 12 – fusion qui ne change rien\"\n",
    "print (merges [] [\"a\", \"b\", \"c\"])\n",
    "print [\"a\", \"b\", \"c\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2943ee28-43f4-4865-a98e-f3dfb85a98d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>/* Styles used for the Hoogle display in the pager */\n",
       ".hoogle-doc {\n",
       "display: block;\n",
       "padding-bottom: 1.3em;\n",
       "padding-left: 0.4em;\n",
       "}\n",
       ".hoogle-code {\n",
       "display: block;\n",
       "font-family: monospace;\n",
       "white-space: pre;\n",
       "}\n",
       ".hoogle-text {\n",
       "display: block;\n",
       "}\n",
       ".hoogle-name {\n",
       "color: green;\n",
       "font-weight: bold;\n",
       "}\n",
       ".hoogle-head {\n",
       "font-weight: bold;\n",
       "}\n",
       ".hoogle-sub {\n",
       "display: block;\n",
       "margin-left: 0.4em;\n",
       "}\n",
       ".hoogle-package {\n",
       "font-weight: bold;\n",
       "font-style: italic;\n",
       "}\n",
       ".hoogle-module {\n",
       "font-weight: bold;\n",
       "}\n",
       ".hoogle-class {\n",
       "font-weight: bold;\n",
       "}\n",
       ".get-type {\n",
       "color: green;\n",
       "font-weight: bold;\n",
       "font-family: monospace;\n",
       "display: block;\n",
       "white-space: pre-wrap;\n",
       "}\n",
       ".show-type {\n",
       "color: green;\n",
       "font-weight: bold;\n",
       "font-family: monospace;\n",
       "margin-left: 1em;\n",
       "}\n",
       ".mono {\n",
       "font-family: monospace;\n",
       "display: block;\n",
       "}\n",
       ".err-msg {\n",
       "color: red;\n",
       "font-style: italic;\n",
       "font-family: monospace;\n",
       "white-space: pre;\n",
       "display: block;\n",
       "}\n",
       "#unshowable {\n",
       "color: red;\n",
       "font-weight: bold;\n",
       "}\n",
       ".err-msg.in.collapse {\n",
       "padding-top: 0.7em;\n",
       "}\n",
       ".highlight-code {\n",
       "white-space: pre;\n",
       "font-family: monospace;\n",
       "}\n",
       ".suggestion-warning { \n",
       "font-weight: bold;\n",
       "color: rgb(200, 130, 0);\n",
       "}\n",
       ".suggestion-error { \n",
       "font-weight: bold;\n",
       "color: red;\n",
       "}\n",
       ".suggestion-name {\n",
       "font-weight: bold;\n",
       "}\n",
       "</style><div class=\"suggestion-name\" style=\"clear:both;\">Use concatMap</div><div class=\"suggestion-row\" style=\"float: left;\"><div class=\"suggestion-warning\">Found:</div><div class=\"highlight-code\" id=\"haskell\">concat (map (\\ i -> Map.findWithDefault \"?\" i idsKey) tokensId)</div></div><div class=\"suggestion-row\" style=\"float: left;\"><div class=\"suggestion-warning\">Why Not:</div><div class=\"highlight-code\" id=\"haskell\">concatMap (\\ i -> Map.findWithDefault \"?\" i idsKey) tokensId</div></div>"
      ],
      "text/plain": [
       "Line 23: Use concatMap\n",
       "Found:\n",
       "concat (map (\\ i -> Map.findWithDefault \"?\" i idsKey) tokensId)\n",
       "Why not:\n",
       "concatMap (\\ i -> Map.findWithDefault \"?\" i idsKey) tokensId"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TESTS DE TOKENIZATION MULTILINGUE\n",
       "==================================\n",
       "\n",
       "=== TEST ANGLAIS ===\n",
       "Texte original: \"hello world\"\n",
       "Tokens: [\"h\",\"e\",\"l\",\"l\",\"o\",\"\\288\",\"w\",\"o\",\"r\",\"l\",\"d\"]\n",
       "Token IDs: [71,68,75,75,78,220,86,78,81,75,67]\n",
       "Reconstructed: \"hello world\"\n",
       "Match: True\n",
       "\n",
       "=== TEST FRANÇAIS ===\n",
       "Texte original: \"bonjour le monde\"\n",
       "Tokens: [\"b\",\"o\",\"n\",\"j\",\"o\",\"u\",\"r\",\"\\288\",\"l\",\"e\",\"\\288\",\"m\",\"o\",\"n\",\"d\",\"e\"]\n",
       "Token IDs: [65,78,77,73,78,84,81,220,75,68,220,76,78,77,67,68]\n",
       "Reconstructed: \"bonjour le monde\"\n",
       "Match: True\n",
       "\n",
       "=== TEST CHINOIS ===\n",
       "Texte original: \"\\20320\\22909 \\19990\\30028\"\n",
       "Tokens: [\"\\20320\",\"\\22909\",\"\\288\",\"\\19990\",\"\\30028\"]\n",
       "Token IDs: [50257,50257,220,50257,50257]\n",
       "Reconstructed: \"smileysmiley smileysmiley\"\n",
       "Match: False\n",
       "\n",
       "=== TEST MIXTE ===\n",
       "Texte original: \"hello bonjour \\20320\\22909\"\n",
       "Tokens: [\"h\",\"e\",\"l\",\"l\",\"o\",\"\\288\",\"b\",\"o\",\"n\",\"j\",\"o\",\"u\",\"r\",\"\\288\",\"\\20320\",\"\\22909\"]\n",
       "Token IDs: [71,68,75,75,78,220,65,78,77,73,78,84,81,220,50257,50257]\n",
       "Reconstructed: \"hello bonjour smileysmiley\"\n",
       "Match: False\n",
       "\n",
       "=== TEST SPECIAL CHARACTER ===\n",
       "Texte original: \"\\233 & \\224 \\232 \\234 \\226 \\251\"\n",
       "Tokens: [\"\\233\",\"\\288\",\"&\",\"\\288\",\"\\224\",\"\\288\",\"\\232\",\"\\288\",\"\\234\",\"\\288\",\"\\226\",\"\\288\",\"\\251\"]\n",
       "Token IDs: [165,220,5,220,156,220,164,220,166,220,158,220,183]\n",
       "Reconstructed: \"\\233 & \\224 \\232 \\234 \\226 \\251\"\n",
       "Match: True\n",
       "\n",
       "=== TEST ROUND-TRIP (aller-retour) ===\n",
       "hello world -> hello world [✓]\n",
       "bonjour monde -> bonjour monde [✓]\n",
       "你好 世界 -> smileysmiley smileysmiley [✗]\n",
       "hello bonjour 你好 -> hello bonjour smileysmiley [✗]\n",
       "é & à è ê â û -> é & à è ê â û [✓]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import qualified Data.Map as Map\n",
    "\n",
    "-- Types\n",
    "type CharMap = Map.Map String Int\n",
    "\n",
    "-- Fonction pour créer un vocabulaire de test simple\n",
    "\n",
    "\n",
    "-- VOS FONCTIONS ORIGINALES (exactement comme vous les avez écrites)\n",
    "changeToIndex :: [String] -> [Int]\n",
    "changeToIndex =\n",
    "    map (\\c -> Map.findWithDefault 50257 c fullVocab)\n",
    "\n",
    "reverseMap :: CharMap -> Map.Map Int String\n",
    "reverseMap vocabMap =\n",
    "    let vocab = Map.toList vocabMap\n",
    "        reverseVocab = map (\\(a, b) -> (b, a)) vocab\n",
    "    in Map.fromList reverseVocab\n",
    "\n",
    "untokenizer :: [Int] -> CharMap -> String\n",
    "untokenizer tokensId strKey =\n",
    "    let idsKey = reverseMap strKey\n",
    "        find = concat (map (\\i -> Map.findWithDefault \"?\" i idsKey) tokensId)\n",
    "        result = T.unpack (T.replace (T.pack \"Ġ\") (T.pack \" \") (T.pack find))\n",
    "    in result\n",
    "\n",
    "-- Fonction pour tokenizer simple - traite chaque string comme un seul token\n",
    "simpleTokenize :: String -> [String]\n",
    "simpleTokenize s = [s]  -- Traite toute la string comme un seul token\n",
    "\n",
    "-- Tests pour différentes langues\n",
    "testEnglish :: IO ()\n",
    "testEnglish = do\n",
    "    putStrLn \"=== TEST ANGLAIS ===\"\n",
    "    let text = \"hello world\"\n",
    "    let tokens = makeStrArray (replaceSpace text)\n",
    "    let tokenIds = changeToIndex tokens\n",
    "    let reconstructed = untokenizer tokenIds fullVocab\n",
    "    \n",
    "    putStrLn $ \"Texte original: \" ++ show text\n",
    "    putStrLn $ \"Tokens: \" ++ show tokens\n",
    "    putStrLn $ \"Token IDs: \" ++ show tokenIds\n",
    "    putStrLn $ \"Reconstructed: \" ++ show reconstructed\n",
    "    putStrLn $ \"Match: \" ++ show (text == reconstructed)\n",
    "    putStrLn \"\"\n",
    "\n",
    "testFrench :: IO ()\n",
    "testFrench = do\n",
    "    putStrLn \"=== TEST FRANÇAIS ===\"\n",
    "    let text = \"bonjour le monde\"\n",
    "    let tokens = makeStrArray (replaceSpace text)\n",
    "    let tokenIds = changeToIndex tokens\n",
    "    let reconstructed = untokenizer tokenIds fullVocab\n",
    "    \n",
    "    putStrLn $ \"Texte original: \" ++ show text\n",
    "    putStrLn $ \"Tokens: \" ++ show tokens\n",
    "    putStrLn $ \"Token IDs: \" ++ show tokenIds\n",
    "    putStrLn $ \"Reconstructed: \" ++ show reconstructed\n",
    "    putStrLn $ \"Match: \" ++ show (text == reconstructed)\n",
    "    putStrLn \"\"\n",
    "\n",
    "testChinese :: IO ()\n",
    "testChinese = do\n",
    "    putStrLn \"=== TEST CHINOIS ===\"\n",
    "    let text = \"你好 世界\"\n",
    "    let tokens = makeStrArray (replaceSpace text)\n",
    "    let tokenIds = changeToIndex tokens\n",
    "    let reconstructed = untokenizer tokenIds fullVocab\n",
    "    \n",
    "    putStrLn $ \"Texte original: \" ++ show text\n",
    "    putStrLn $ \"Tokens: \" ++ show tokens  \n",
    "    putStrLn $ \"Token IDs: \" ++ show tokenIds\n",
    "    putStrLn $ \"Reconstructed: \" ++ show reconstructed\n",
    "    putStrLn $ \"Match: \" ++ show (text == reconstructed)\n",
    "    putStrLn \"\"\n",
    "\n",
    "testMixed :: IO ()\n",
    "testMixed = do\n",
    "    putStrLn \"=== TEST MIXTE ===\"\n",
    "    let text = \"hello bonjour 你好\"\n",
    "    let tokens = makeStrArray (replaceSpace text)\n",
    "    let tokenIds = changeToIndex tokens\n",
    "    let reconstructed = untokenizer tokenIds fullVocab\n",
    "    \n",
    "    putStrLn $ \"Texte original: \" ++ show text\n",
    "    putStrLn $ \"Tokens: \" ++ show tokens\n",
    "    putStrLn $ \"Token IDs: \" ++ show tokenIds\n",
    "    putStrLn $ \"Reconstructed: \" ++ show reconstructed\n",
    "    putStrLn $ \"Match: \" ++ show (text == reconstructed)\n",
    "    putStrLn \"\"\n",
    "    \n",
    "testChar :: IO ()\n",
    "testChar = do\n",
    "    putStrLn \"=== TEST SPECIAL CHARACTER ===\"\n",
    "    let text = \"é & à è ê â û\"\n",
    "    let tokens = makeStrArray (replaceSpace text)\n",
    "    let tokenIds = changeToIndex tokens\n",
    "    let reconstructed = untokenizer tokenIds fullVocab\n",
    "    \n",
    "    putStrLn $ \"Texte original: \" ++ show text\n",
    "    putStrLn $ \"Tokens: \" ++ show tokens\n",
    "    putStrLn $ \"Token IDs: \" ++ show tokenIds\n",
    "    putStrLn $ \"Reconstructed: \" ++ show reconstructed\n",
    "    putStrLn $ \"Match: \" ++ show (text == reconstructed)\n",
    "    putStrLn \"\"\n",
    "\n",
    "\n",
    "testRoundTrip :: IO ()\n",
    "testRoundTrip = do\n",
    "    putStrLn \"=== TEST ROUND-TRIP (aller-retour) ===\"\n",
    "    let texts = [\n",
    "            \"hello world\",\n",
    "            \"bonjour monde\", \n",
    "            \"你好 世界\",\n",
    "            \"hello bonjour 你好\",\n",
    "            \"é & à è ê â û\"]\n",
    "    \n",
    "    mapM_ (\\text -> do\n",
    "        let tokens = makeStrArray (replaceSpace text)\n",
    "        let tokenIds = changeToIndex tokens\n",
    "        let reconstructed = untokenizer tokenIds fullVocab\n",
    "        let success = text == reconstructed\n",
    "        putStrLn $ text ++ \" -> \" ++ reconstructed ++ \" [\" ++ \n",
    "                  (if success then \"✓\" else \"✗\") ++ \"]\"\n",
    "        ) texts\n",
    "    putStrLn \"\"\n",
    "\n",
    "-- Test principal\n",
    "main :: IO ()\n",
    "main = do\n",
    "    putStrLn \"TESTS DE TOKENIZATION MULTILINGUE\"\n",
    "    putStrLn \"==================================\"\n",
    "    putStrLn \"\"\n",
    "    \n",
    "    testEnglish\n",
    "    testFrench\n",
    "    testChinese\n",
    "    testMixed\n",
    "    testChar\n",
    "    testRoundTrip\n",
    "\n",
    "\n",
    "main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9e2fd4c8-d59a-4449-842e-0bb0ea629c5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TESTS DE TOKENIZATION MULTILINGUE\n",
       "==================================\n",
       "\n",
       "=== TEST ANGLAIS ===\n",
       "Texte original: \"hello world\"\n",
       "Tokens: [\"h\",\"e\",\"l\",\"l\",\"o\",\"\\288\",\"w\",\"o\",\"r\",\"l\",\"d\"]\n",
       "Merged: [\"hello\",\"\\288world\"]\n",
       "Token IDs: [31373,995]\n",
       "Token GPT2: [\"hello\",\"\\288world\"]\n",
       "Match: True\n",
       "\n",
       "=== TEST FRANÇAIS ===\n",
       "Texte original: \"bonjour le monde\"\n",
       "Tokens: [\"b\",\"o\",\"n\",\"j\",\"o\",\"u\",\"r\",\"\\288\",\"l\",\"e\",\"\\288\",\"m\",\"o\",\"n\",\"d\",\"e\"]\n",
       "Merged: [\"bon\",\"j\",\"our\",\"\\288le\",\"\\288m\",\"onde\"]\n",
       "Token IDs: [4189,73,454,443,285,14378]\n",
       "Token GPT2: [\"bon\",\"j\",\"our\",\"\\288le\",\"\\288m\",\"onde\"]\n",
       "Match: True\n",
       "\n",
       "=== TEST CHINOIS ===\n",
       "Texte original: \"\\20320\\22909 \\19990\\30028\"\n",
       "Tokens: [\"\\20320\",\"\\22909\",\"\\288\",\"\\19990\",\"\\30028\"]\n",
       "Merged: [\"\\20320\",\"\\22909\",\"\\288\",\"\\19990\",\"\\30028\"]\n",
       "Token IDs: [50257,50257,220,50257,50257]\n",
       "Token GPT2: [\"\\228\\189\",\"\\322\",\"\\229\\165\",\"\\189\",\"\\288\",\"\\228\\184\",\"\\312\",\"\\231\\311\",\"\\302\"]\n",
       "Match: False\n",
       "\n",
       "=== TEST MIXTE ===\n",
       "Texte original: \"hello bonjour \\20320\\22909\"\n",
       "Tokens: [\"h\",\"e\",\"l\",\"l\",\"o\",\"\\288\",\"b\",\"o\",\"n\",\"j\",\"o\",\"u\",\"r\",\"\\288\",\"\\20320\",\"\\22909\"]\n",
       "Merged: [\"hello\",\"\\288bon\",\"j\",\"our\",\"\\288\",\"\\20320\",\"\\22909\"]\n",
       "Token IDs: [31373,5351,73,454,220,50257,50257]\n",
       "Token GPT2: [\"hello\",\"\\288bon\",\"j\",\"our\",\"\\288\",\"\\228\\189\",\"\\322\",\"\\229\\165\",\"\\189\"]\n",
       "Match: False\n",
       "\n",
       "=== TEST SPECIAL CHARACTER ===\n",
       "Texte original: \"\\233 & \\224 \\232 \\234 \\226 \\251\"\n",
       "Tokens: [\"\\233\",\"\\288\",\"&\",\"\\288\",\"\\224\",\"\\288\",\"\\232\",\"\\288\",\"\\234\",\"\\288\",\"\\226\",\"\\288\",\"\\251\"]\n",
       "Merged: [\"\\233\",\"\\288&\",\"\\288\",\"\\224\",\"\\288\\232\",\"\\288\",\"\\234\",\"\\288\\226\",\"\\288\",\"\\251\"]\n",
       "Token IDs: [165,1222,220,156,5525,220,166,2343,220,183]\n",
       "Token GPT2: [\"\\195\\169\",\"\\288&\",\"\\288\\195\\322\",\"\\288\\195\",\"\\168\",\"\\288\\195\",\"\\170\",\"\\288\\195\",\"\\162\",\"\\288\\195\",\"\\187\"]\n",
       "Match: False\n",
       "\n",
       "=== TEST LONG TEXTE ===\n",
       "Texte original: \"Ce matin, j\\8217ai \\233t\\233 \\224 l\\8217\\233cole avec \\201lodie. Il faisait beau et le ciel \\233tait d\\8217un bleu profond. \\192 la pause, nous avons bu un caf\\233 tr\\232s fort. C\\8217\\233tait vraiment une belle journ\\233e d\\8217\\233t\\233!\"\n",
       "Tokens: [\"C\",\"e\",\"\\288\",\"m\",\"a\",\"t\",\"i\",\"n\",\",\",\"\\288\",\"j\",\"\\8217\",\"a\",\"i\",\"\\288\",\"\\233\",\"t\",\"\\233\",\"\\288\",\"\\224\",\"\\288\",\"l\",\"\\8217\",\"\\233\",\"c\",\"o\",\"l\",\"e\",\"\\288\",\"a\",\"v\",\"e\",\"c\",\"\\288\",\"\\201\",\"l\",\"o\",\"d\",\"i\",\"e\",\".\",\"\\288\",\"I\",\"l\",\"\\288\",\"f\",\"a\",\"i\",\"s\",\"a\",\"i\",\"t\",\"\\288\",\"b\",\"e\",\"a\",\"u\",\"\\288\",\"e\",\"t\",\"\\288\",\"l\",\"e\",\"\\288\",\"c\",\"i\",\"e\",\"l\",\"\\288\",\"\\233\",\"t\",\"a\",\"i\",\"t\",\"\\288\",\"d\",\"\\8217\",\"u\",\"n\",\"\\288\",\"b\",\"l\",\"e\",\"u\",\"\\288\",\"p\",\"r\",\"o\",\"f\",\"o\",\"n\",\"d\",\".\",\"\\288\",\"\\192\",\"\\288\",\"l\",\"a\",\"\\288\",\"p\",\"a\",\"u\",\"s\",\"e\",\",\",\"\\288\",\"n\",\"o\",\"u\",\"s\",\"\\288\",\"a\",\"v\",\"o\",\"n\",\"s\",\"\\288\",\"b\",\"u\",\"\\288\",\"u\",\"n\",\"\\288\",\"c\",\"a\",\"f\",\"\\233\",\"\\288\",\"t\",\"r\",\"\\232\",\"s\",\"\\288\",\"f\",\"o\",\"r\",\"t\",\".\",\"\\288\",\"C\",\"\\8217\",\"\\233\",\"t\",\"a\",\"i\",\"t\",\"\\288\",\"v\",\"r\",\"a\",\"i\",\"m\",\"e\",\"n\",\"t\",\"\\288\",\"u\",\"n\",\"e\",\"\\288\",\"b\",\"e\",\"l\",\"l\",\"e\",\"\\288\",\"j\",\"o\",\"u\",\"r\",\"n\",\"\\233\",\"e\",\"\\288\",\"d\",\"\\8217\",\"\\233\",\"t\",\"\\233\",\"!\"]\n",
       "Merged: [\"C\",\"e\",\"\\288mat\",\"in\",\",\",\"\\288j\",\"\\8217\",\"ai\",\"\\288\\233\",\"t\",\"\\233\",\"\\288\",\"\\224\",\"\\288l\",\"\\8217\",\"\\233\",\"co\",\"le\",\"\\288a\",\"vec\",\"\\288\",\"\\201\",\"l\",\"od\",\"ie\",\".\",\"\\288Il\",\"\\288f\",\"ais\",\"ait\",\"\\288be\",\"au\",\"\\288et\",\"\\288le\",\"\\288c\",\"iel\",\"\\288\\233\",\"t\",\"ait\",\"\\288d\",\"\\8217\",\"un\",\"\\288ble\",\"u\",\"\\288prof\",\"ond\",\".\",\"\\288\",\"\\192\",\"\\288la\",\"\\288pause\",\",\",\"\\288n\",\"ous\",\"\\288av\",\"ons\",\"\\288bu\",\"\\288un\",\"\\288caf\",\"\\233\",\"\\288tr\",\"\\232\",\"s\",\"\\288fort\",\".\",\"\\288C\",\"\\8217\",\"\\233\",\"t\",\"ait\",\"\\288v\",\"ra\",\"iment\",\"\\288une\",\"\\288bel\",\"le\",\"\\288j\",\"ourn\",\"\\233\",\"e\",\"\\288d\",\"\\8217\",\"\\233\",\"t\",\"\\233\",\"!\"]\n",
       "Token IDs: [34,68,2603,259,11,474,50257,1872,16268,83,165,220,156,300,50257,165,1073,293,257,35138,220,133,75,375,494,13,13778,277,15152,4548,307,559,2123,443,269,8207,16268,83,4548,288,50257,403,7245,84,1534,623,13,220,124,8591,14985,11,299,516,1196,684,809,555,19945,165,491,164,82,6285,13,327,50257,165,83,4548,410,430,3681,17809,894,293,474,1798,165,68,288,50257,165,83,165,0]\n",
       "Token GPT2: [\"C\",\"e\",\"\\288mat\",\"in\",\",\",\"\\288j\",\"\\226\\290\",\"\\315\",\"ai\",\"\\288\",\"\\195\\169t\",\"\\195\\169\",\"\\288\\195\\322\",\"\\288l\",\"\\226\\290\",\"\\315\",\"\\195\\169\",\"co\",\"le\",\"\\288a\",\"vec\",\"\\288\\195\\299\",\"l\",\"od\",\"ie\",\".\",\"\\288Il\",\"\\288f\",\"ais\",\"ait\",\"\\288be\",\"au\",\"\\288et\",\"\\288le\",\"\\288c\",\"iel\",\"\\288\",\"\\195\\169t\",\"ait\",\"\\288d\",\"\\226\\290\",\"\\315\",\"un\",\"\\288ble\",\"u\",\"\\288prof\",\"ond\",\".\",\"\\288\\195\",\"\\290\",\"\\288la\",\"\\288pause\",\",\",\"\\288n\",\"ous\",\"\\288av\",\"ons\",\"\\288bu\",\"\\288un\",\"\\288caf\\195\\169\",\"\\288tr\",\"\\195\\168\",\"s\",\"\\288fort\",\".\",\"\\288C\",\"\\226\\290\",\"\\315\",\"\\195\\169t\",\"ait\",\"\\288v\",\"ra\",\"iment\",\"\\288une\",\"\\288bel\",\"le\",\"j\",\"ourn\",\"\\195\\169e\",\"\\288d\",\"\\226\\290\",\"\\315\",\"\\195\\169t\",\"\\195\\169\",\"!\"]\n",
       "Match: False\n",
       "\n",
       "=== TEST LONG TEXTE SANS ACCENT===\n",
       "Texte original: \"Ce matin, j'ai ete a l'ecole avec Elodie. Il faisait beau et le ciel etait d'un bleu profond. A la pause, nous avons bu un cafe tres fort. C'etait vraiment une belle journee d'ete!\"\n",
       "Tokens: [\"C\",\"e\",\"\\288\",\"m\",\"a\",\"t\",\"i\",\"n\",\",\",\"\\288\",\"j\",\"'\",\"a\",\"i\",\"\\288\",\"e\",\"t\",\"e\",\"\\288\",\"a\",\"\\288\",\"l\",\"'\",\"e\",\"c\",\"o\",\"l\",\"e\",\"\\288\",\"a\",\"v\",\"e\",\"c\",\"\\288\",\"E\",\"l\",\"o\",\"d\",\"i\",\"e\",\".\",\"\\288\",\"I\",\"l\",\"\\288\",\"f\",\"a\",\"i\",\"s\",\"a\",\"i\",\"t\",\"\\288\",\"b\",\"e\",\"a\",\"u\",\"\\288\",\"e\",\"t\",\"\\288\",\"l\",\"e\",\"\\288\",\"c\",\"i\",\"e\",\"l\",\"\\288\",\"e\",\"t\",\"a\",\"i\",\"t\",\"\\288\",\"d\",\"'\",\"u\",\"n\",\"\\288\",\"b\",\"l\",\"e\",\"u\",\"\\288\",\"p\",\"r\",\"o\",\"f\",\"o\",\"n\",\"d\",\".\",\"\\288\",\"A\",\"\\288\",\"l\",\"a\",\"\\288\",\"p\",\"a\",\"u\",\"s\",\"e\",\",\",\"\\288\",\"n\",\"o\",\"u\",\"s\",\"\\288\",\"a\",\"v\",\"o\",\"n\",\"s\",\"\\288\",\"b\",\"u\",\"\\288\",\"u\",\"n\",\"\\288\",\"c\",\"a\",\"f\",\"e\",\"\\288\",\"t\",\"r\",\"e\",\"s\",\"\\288\",\"f\",\"o\",\"r\",\"t\",\".\",\"\\288\",\"C\",\"'\",\"e\",\"t\",\"a\",\"i\",\"t\",\"\\288\",\"v\",\"r\",\"a\",\"i\",\"m\",\"e\",\"n\",\"t\",\"\\288\",\"u\",\"n\",\"e\",\"\\288\",\"b\",\"e\",\"l\",\"l\",\"e\",\"\\288\",\"j\",\"o\",\"u\",\"r\",\"n\",\"e\",\"e\",\"\\288\",\"d\",\"'\",\"e\",\"t\",\"e\",\"!\"]\n",
       "Merged: [\"C\",\"e\",\"\\288mat\",\"in\",\",\",\"\\288j\",\"'\",\"ai\",\"\\288e\",\"te\",\"\\288a\",\"\\288l\",\"'\",\"ec\",\"ole\",\"\\288a\",\"vec\",\"\\288El\",\"od\",\"ie\",\".\",\"\\288Il\",\"\\288f\",\"ais\",\"ait\",\"\\288be\",\"au\",\"\\288et\",\"\\288le\",\"\\288c\",\"iel\",\"\\288et\",\"ait\",\"\\288d\",\"'\",\"un\",\"\\288ble\",\"u\",\"\\288prof\",\"ond\",\".\",\"\\288A\",\"\\288la\",\"\\288pause\",\",\",\"\\288n\",\"ous\",\"\\288av\",\"ons\",\"\\288bu\",\"\\288un\",\"\\288cafe\",\"\\288t\",\"res\",\"\\288fort\",\".\",\"\\288C\",\"'\",\"et\",\"ait\",\"\\288v\",\"ra\",\"iment\",\"\\288une\",\"\\288bel\",\"le\",\"\\288jour\",\"nee\",\"\\288d\",\"'\",\"ete\",\"!\"]\n",
       "Token IDs: [34,68,2603,259,11,474,6,1872,304,660,257,300,6,721,2305,257,35138,2574,375,494,13,13778,277,15152,4548,307,559,2123,443,269,8207,2123,4548,288,6,403,7245,84,1534,623,13,317,8591,14985,11,299,516,1196,684,809,555,26725,256,411,6285,13,327,6,316,4548,410,430,3681,17809,894,293,30068,21381,288,6,14471,0]\n",
       "Token GPT2: [\"C\",\"e\",\"\\288mat\",\"in\",\",\",\"\\288j\",\"'\",\"ai\",\"\\288e\",\"te\",\"\\288a\",\"\\288l\",\"'\",\"ec\",\"ole\",\"\\288a\",\"vec\",\"\\288El\",\"od\",\"ie\",\".\",\"\\288Il\",\"\\288f\",\"ais\",\"ait\",\"\\288be\",\"au\",\"\\288et\",\"\\288le\",\"\\288c\",\"iel\",\"\\288et\",\"ait\",\"\\288d\",\"'\",\"un\",\"\\288ble\",\"u\",\"\\288prof\",\"ond\",\".\",\"\\288A\",\"\\288la\",\"\\288pause\",\",\",\"\\288n\",\"ous\",\"\\288av\",\"ons\",\"\\288bu\",\"\\288un\",\"\\288cafe\",\"\\288t\",\"res\",\"\\288fort\",\".\",\"\\288C\",\"'\",\"et\",\"ait\",\"\\288v\",\"ra\",\"iment\",\"\\288une\",\"\\288bel\",\"le\",\"\\288jour\",\"nee\",\"\\288d\",\"'\",\"ete\",\"!\"]\n",
       "Match: True\n",
       "\n",
       "=== TEST ROUND-TRIP (aller-retour) ===\n",
       "hello world -> hello world [✓]\n",
       "bonjour monde -> bonjour monde [✓]\n",
       "你好 世界 -> smileysmiley smileysmiley [✗]\n",
       "hello bonjour 你好 -> hello bonjour smileysmiley [✗]\n",
       "é & à è ê â û -> é & à è ê â û [✓]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import qualified Data.Map as Map\n",
    "\n",
    "-- Types\n",
    "type CharMap = Map.Map String Int\n",
    "\n",
    "\n",
    "-- Tests pour différentes langues\n",
    "testEnglish :: IO ()\n",
    "testEnglish = do\n",
    "    putStrLn \"=== TEST ANGLAIS ===\"\n",
    "    let text = \"hello world\"\n",
    "    let tokens = makeStrArray (replaceSpace text)\n",
    "    let merged = merges pairs tokens\n",
    "    let tokenIds = changeToIndex merged\n",
    "    let tokenGPT2 = [\"hello\", \"Ġworld\"]\n",
    "    \n",
    "    putStrLn $ \"Texte original: \" ++ show text\n",
    "    putStrLn $ \"Tokens: \" ++ show tokens\n",
    "    putStrLn $ \"Merged: \" ++ show merged\n",
    "    putStrLn $ \"Token IDs: \" ++ show tokenIds\n",
    "    putStrLn $ \"Token GPT2: \" ++ show tokenGPT2\n",
    "    putStrLn $ \"Match: \" ++ show (merged == tokenGPT2)\n",
    "    putStrLn \"\"\n",
    "\n",
    "testFrench :: IO ()\n",
    "testFrench = do\n",
    "    putStrLn \"=== TEST FRANÇAIS ===\"\n",
    "    let text = \"bonjour le monde\"\n",
    "    let tokens = makeStrArray (replaceSpace text)\n",
    "    let merged = merges pairs tokens\n",
    "    let tokenIds = changeToIndex merged\n",
    "    let tokenGPT2 = [\"bon\", \"j\", \"our\", \"Ġle\", \"Ġm\", \"onde\"]\n",
    "    \n",
    "    putStrLn $ \"Texte original: \" ++ show text\n",
    "    putStrLn $ \"Tokens: \" ++ show tokens\n",
    "    putStrLn $ \"Merged: \" ++ show merged\n",
    "    putStrLn $ \"Token IDs: \" ++ show tokenIds\n",
    "    putStrLn $ \"Token GPT2: \" ++ show tokenGPT2    \n",
    "    putStrLn $ \"Match: \" ++ show (merged == tokenGPT2)\n",
    "    putStrLn \"\"\n",
    "\n",
    "testChinese :: IO ()\n",
    "testChinese = do\n",
    "    putStrLn \"=== TEST CHINOIS ===\"\n",
    "    let text = \"你好 世界\"\n",
    "    let tokens = makeStrArray (replaceSpace text)\n",
    "    let merged = merges pairs tokens\n",
    "    let tokenIds = changeToIndex merged\n",
    "    let tokenGPT2 = [\"ä½\", \"ł\", \"å¥\", \"½\", \"Ġ\", \"ä¸\", \"ĸ\", \"çķ\", \"Į\"]\n",
    "    \n",
    "    putStrLn $ \"Texte original: \" ++ show text\n",
    "    putStrLn $ \"Tokens: \" ++ show tokens  \n",
    "    putStrLn $ \"Merged: \" ++ show merged\n",
    "    putStrLn $ \"Token IDs: \" ++ show tokenIds\n",
    "    putStrLn $ \"Token GPT2: \" ++ show tokenGPT2    \n",
    "    putStrLn $ \"Match: \" ++ show (merged == tokenGPT2)\n",
    "    putStrLn \"\"\n",
    "\n",
    "testMixed :: IO ()\n",
    "testMixed = do\n",
    "    putStrLn \"=== TEST MIXTE ===\"\n",
    "    let text = \"hello bonjour 你好\"\n",
    "    let tokens = makeStrArray (replaceSpace text)\n",
    "    let merged = merges pairs tokens\n",
    "    let tokenIds = changeToIndex merged\n",
    "    let tokenGPT2 = [\"hello\", \"Ġbon\", \"j\", \"our\", \"Ġ\", \"ä½\", \"ł\", \"å¥\", \"½\"]\n",
    "    \n",
    "    putStrLn $ \"Texte original: \" ++ show text\n",
    "    putStrLn $ \"Tokens: \" ++ show tokens\n",
    "    putStrLn $ \"Merged: \" ++ show merged\n",
    "    putStrLn $ \"Token IDs: \" ++ show tokenIds\n",
    "    putStrLn $ \"Token GPT2: \" ++ show tokenGPT2    \n",
    "    putStrLn $ \"Match: \" ++ show (merged == tokenGPT2)\n",
    "    putStrLn \"\"\n",
    "    \n",
    "testChar :: IO ()\n",
    "testChar = do\n",
    "    putStrLn \"=== TEST SPECIAL CHARACTER ===\"\n",
    "    let text = \"é & à è ê â û\"\n",
    "    let tokens = makeStrArray (replaceSpace text)\n",
    "    let merged = merges pairs tokens\n",
    "    let tokenIds = changeToIndex merged\n",
    "    let tokenGPT2 = [\"Ã©\", \"Ġ&\", \"ĠÃł\", \"ĠÃ\", \"¨\", \"ĠÃ\", \"ª\", \"ĠÃ\", \"¢\", \"ĠÃ\", \"»\"]\n",
    "\n",
    "    putStrLn $ \"Texte original: \" ++ show text\n",
    "    putStrLn $ \"Tokens: \" ++ show tokens\n",
    "    putStrLn $ \"Merged: \" ++ show merged\n",
    "    putStrLn $ \"Token IDs: \" ++ show tokenIds\n",
    "    putStrLn $ \"Token GPT2: \" ++ show tokenGPT2\n",
    "    putStrLn $ \"Match: \" ++ show (merged == tokenGPT2)\n",
    "    putStrLn \"\"\n",
    "\n",
    "testLongAccent :: IO ()\n",
    "testLongAccent = do\n",
    "    putStrLn \"=== TEST LONG TEXTE ===\"\n",
    "    let text = \"Ce matin, j’ai été à l’école avec Élodie. Il faisait beau et le ciel était d’un bleu profond. À la pause, nous avons bu un café très fort. C’était vraiment une belle journée d’été!\"\n",
    "    let tokens = makeStrArray (replaceSpace text)\n",
    "    let merged = merges pairs tokens\n",
    "    let tokenIds = changeToIndex merged\n",
    "    let tokenGPT2 = [\"C\", \"e\", \"Ġmat\", \"in\", \",\", \"Ġj\", \"âĢ\", \"Ļ\", \"ai\", \"Ġ\", \"Ã©t\", \"Ã©\", \"ĠÃł\", \"Ġl\", \"âĢ\", \"Ļ\", \"Ã©\", \"co\", \"le\", \"Ġa\", \"vec\", \"ĠÃī\", \"l\", \"od\", \"ie\", \".\", \"ĠIl\", \"Ġf\", \"ais\", \"ait\", \"Ġbe\", \"au\", \"Ġet\", \"Ġle\", \"Ġc\", \"iel\", \"Ġ\", \"Ã©t\", \"ait\", \"Ġd\", \"âĢ\", \"Ļ\", \"un\", \"Ġble\", \"u\", \"Ġprof\", \"ond\", \".\", \"ĠÃ\", \"Ģ\", \"Ġla\", \"Ġpause\", \",\", \"Ġn\", \"ous\", \"Ġav\", \"ons\", \"Ġbu\", \"Ġun\", \"ĠcafÃ©\", \"Ġtr\", \"Ã¨\", \"s\", \"Ġfort\", \".\", \"ĠC\", \"âĢ\", \"Ļ\", \"Ã©t\", \"ait\", \"Ġv\", \"ra\", \"iment\", \"Ġune\", \"Ġbel\", \"le\", \"j\", \"ourn\", \"Ã©e\", \"Ġd\", \"âĢ\", \"Ļ\", \"Ã©t\", \"Ã©\", \"!\"]\n",
    "\n",
    "    putStrLn $ \"Texte original: \" ++ show text\n",
    "    putStrLn $ \"Tokens: \" ++ show tokens\n",
    "    putStrLn $ \"Merged: \" ++ show merged\n",
    "    putStrLn $ \"Token IDs: \" ++ show tokenIds\n",
    "    putStrLn $ \"Token GPT2: \" ++ show tokenGPT2\n",
    "    putStrLn $ \"Match: \" ++ show (merged == tokenGPT2)\n",
    "    putStrLn \"\"\n",
    "    \n",
    "testLong :: IO ()\n",
    "testLong = do\n",
    "    putStrLn \"=== TEST LONG TEXTE SANS ACCENT===\"\n",
    "    let text = \"Ce matin, j'ai ete a l'ecole avec Elodie. Il faisait beau et le ciel etait d'un bleu profond. A la pause, nous avons bu un cafe tres fort. C'etait vraiment une belle journee d'ete!\"\n",
    "    let tokens = makeStrArray (replaceSpace text)\n",
    "    let merged = merges pairs tokens\n",
    "    let tokenIds = changeToIndex merged\n",
    "    let tokenGPT2 = [\"C\", \"e\", \"Ġmat\", \"in\", \",\", \"Ġj\", \"'\", \"ai\", \"Ġe\", \"te\", \"Ġa\", \"Ġl\", \"'\", \"ec\", \"ole\", \"Ġa\", \"vec\", \"ĠEl\", \"od\", \"ie\", \".\", \"ĠIl\", \"Ġf\", \"ais\", \"ait\", \"Ġbe\", \"au\", \"Ġet\", \"Ġle\", \"Ġc\", \"iel\", \"Ġet\", \"ait\", \"Ġd\", \"'\", \"un\", \"Ġble\", \"u\", \"Ġprof\", \"ond\", \".\",  \"ĠA\", \"Ġla\", \"Ġpause\", \",\", \"Ġn\", \"ous\", \"Ġav\", \"ons\", \"Ġbu\", \"Ġun\", \"Ġcafe\", \"Ġt\", \"res\", \"Ġfort\", \".\",  \"ĠC\", \"'\", \"et\", \"ait\", \"Ġv\", \"ra\", \"iment\", \"Ġune\", \"Ġbel\", \"le\", \"Ġjour\", \"nee\", \"Ġd\", \"'\", \"ete\", \"!\"]\n",
    "\n",
    "    putStrLn $ \"Texte original: \" ++ show text\n",
    "    putStrLn $ \"Tokens: \" ++ show tokens\n",
    "    putStrLn $ \"Merged: \" ++ show merged\n",
    "    putStrLn $ \"Token IDs: \" ++ show tokenIds\n",
    "    putStrLn $ \"Token GPT2: \" ++ show tokenGPT2\n",
    "    putStrLn $ \"Match: \" ++ show (merged == tokenGPT2)\n",
    "    putStrLn \"\"\n",
    "    \n",
    "    \n",
    "-- Test principal\n",
    "main :: IO ()\n",
    "main = do\n",
    "    putStrLn \"TESTS DE TOKENIZATION MULTILINGUE\"\n",
    "    putStrLn \"==================================\"\n",
    "    putStrLn \"\"\n",
    "    \n",
    "    testEnglish\n",
    "    testFrench\n",
    "    testChinese\n",
    "    testMixed\n",
    "    testChar\n",
    "    testLongAccent\n",
    "    testLong\n",
    "    testRoundTrip\n",
    "\n",
    "\n",
    "main"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Haskell",
   "language": "haskell",
   "name": "haskell"
  },
  "language_info": {
   "codemirror_mode": "ihaskell",
   "file_extension": ".hs",
   "mimetype": "text/x-haskell",
   "name": "haskell",
   "pygments_lexer": "Haskell",
   "version": "9.2.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
